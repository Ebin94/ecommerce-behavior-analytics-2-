{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2d3b01",
   "metadata": {},
   "source": [
    "# Modelling: High Value and Satisfaction Prediction\n",
    "\n",
    "This notebook fits logistic regression and XGBoost classifiers to predict whether a customer is high value or satisfied. It reports accuracy and ROC–AUC metrics and displays feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load cleaned data\n",
    "df = pd.read_csv('../data/processed/customers_clean.csv', parse_dates=['purchase_date'])\n",
    "\n",
    "# Define categorical and numeric columns\n",
    "categorical_cols = ['gender','city','membership_type','discount_applied']\n",
    "numeric_cols = ['age','total_spend','items_purchased','avg_rating','days_since_last_purchase']\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
    "    ('num', 'passthrough', numeric_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High‑value classification\n",
    "X = df[categorical_cols + numeric_cols]\n",
    "y = df['is_high_value']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_prob = log_reg.predict_proba(X_test)[:,1]\n",
    "print('High‑value accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('High‑value ROC‑AUC:', roc_auc_score(y_test, y_prob))\n",
    "print('Confusion matrix:\n",
    "', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decabe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model for high‑value classification\n",
    "xgb = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_prob_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "print('XGBoost accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('XGBoost ROC‑AUC:', roc_auc_score(y_test, y_prob_xgb))\n",
    "print('Confusion matrix:\n",
    "', confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc76f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satisfaction classification\n",
    "X = df[categorical_cols + numeric_cols]\n",
    "y = df['satisfaction_level'].eq('Satisfied')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg_s = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_s.fit(X_train, y_train)\n",
    "y_pred_s = log_reg_s.predict(X_test)\n",
    "y_prob_s = log_reg_s.predict_proba(X_test)[:,1]\n",
    "print('Satisfaction accuracy:', accuracy_score(y_test, y_pred_s))\n",
    "print('Satisfaction ROC‑AUC:', roc_auc_score(y_test, y_prob_s))\n",
    "print('Confusion matrix:\n",
    "', confusion_matrix(y_test, y_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c628875",
   "metadata": {},
   "source": [
    "The logistic regression and XGBoost classifiers achieve very high accuracy and ROC–AUC scores on this small dataset. This indicates that the problem is easy to separate given the provided features. In a production setting you would validate models on a larger, independent dataset and consider additional features to avoid overfitting."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
